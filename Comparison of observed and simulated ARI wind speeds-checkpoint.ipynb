{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of observed and simulated ARI wind speeds\n",
    "\n",
    "This notebook plots the average recurrence interval (ARI) wind speeds based on observed wind speeds corresponding to the passage of TCs (within 200 km of a station). It adds a plot of the fitted ARI wind speeds from a TCRM simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "from os.path import join as pjoin\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "from extremes import returnLevels, empReturnPeriod\n",
    "from distributions import fittedPDF\n",
    "\n",
    "# Import widgets for interactive notebook\n",
    "from ipywidgets import interact, fixed, Checkbox\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadObservations(stnId):\n",
    "    \"\"\"\n",
    "    Load the observations from file for a given BoM station, where the observations have\n",
    "    been selected from the complete digital history of daily maximum wind speeds, where a cyclone has \n",
    "    passed within 200 km of the station, and the station was open at the time of passage.\n",
    "    \n",
    "    :param int stnId: Bureau of Meteorology Station identification number\n",
    "    \n",
    "    :returns: data frame containing the gust wind speed, direction and cyclone name\n",
    "              based on passage of cyclones near the selected station. If no observation\n",
    "              file is found (`Exception.FileNotFoundError`), return `None`\n",
    "    \"\"\"\n",
    "    \n",
    "    names = ['recid', 'stnId', 'datetime', 'gust',\n",
    "             'direction', 'quality', 'cycName', 'cycId']\n",
    "    \n",
    "    filename = pjoin(obsPath, \"bom_{0:06d}.csv\".format(stnId))\n",
    "    try:\n",
    "        obsdf = pd.read_csv(filename, skiprows=1, names=names,\n",
    "                            parse_dates=[2], infer_datetime_format=True)\n",
    "    except IOError:\n",
    "        print(\"No data file for stnId: {0}\".format(stnId))\n",
    "        return None\n",
    "    return obsdf\n",
    "\n",
    "def getStationDates(stnId):\n",
    "    \"\"\"\n",
    "    Retrieve the length of observed record in years, based on the start and end dates\n",
    "    of the observational data. \n",
    "    \n",
    "    :param int stnId: Bureau of Meteorology Station identification number\n",
    "    \n",
    "    :returns: number of years between the start and end of the data on file.\n",
    "    \"\"\"\n",
    "    startYear = stndf.loc[stnId]['stnDataStart']\n",
    "    endYear = stndf.loc[stnId]['stnDataEnd']\n",
    "    numYears = endYear - startYear + 1\n",
    "    return numYears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STNTYPES = [('st', 'S2'), ('stnId', 'i'), ('stnDistCode', 'S4'), ('stnName', 'S'), \n",
    "            ('stnDateOpen', 'S10'), ('stnDateClosed', 'S10'), ('stnLat', 'f8'), \n",
    "            ('stnLon', 'f8'), ('method', 'S15'), ('state', 'S3'), \n",
    "            ('stnElevation', 'f8'), ('baroElev', 'i'), ('stnWMONumber', 'i'), ('stnDataStart', 'i'), \n",
    "            ('stnDataEnd', 'i'), ('blank', 'S3'), ('percentcomplete', 'f8'), ('pcqualy', 'f8'), \n",
    "            ('pcqualn', 'f8'), ('pcqualw', 'f8'), ('pcquals', 'f8'), ('pcquali', 'f8'), ('end', 'S1')]\n",
    "STNCONVERT = {'stnName' : str.rstrip}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with loading the observation station information. This is from the daily maximum wind gust dataset (Geosciene Australia eCat #110561), starting with the station details file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsPath = \"X:/georisk/HaRIA_B_Wind/projects/tcha/data/derived/observations/daily\"\n",
    "stationFilePath = \"X:/georisk/HaRIA_B_Wind/data/raw/from_bom/daily/2017/\"\n",
    "stnfile = pjoin(stationFilePath, \"DC02D_StnDet_999999999425050.txt\")\n",
    "\n",
    "stndf = pd.read_csv(stnfile, parse_dates=[4, 5],\n",
    "                        usecols=(1,2,3,4,5,6,7,9,10,12,13,14,16), \n",
    "                        names = np.dtype(STNTYPES).names,\n",
    "                        skiprows=1, engine='python', index_col='stnId', \n",
    "                        converters=STNCONVERT)\n",
    "stationNameList = list(stndf['stnName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load a shape file that contains the observed stations joined with the TCRM simulation locations. Note in this dataframe, we need to add an index, and so we index by both the location id number (TCRM simulation locations) *and* the station number (observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locationFilePath = r\"\\\\prod.lan\\active\\ops\\community_safety\\georisk\\HaRIA_B_Wind\\projects\\tcha\\data\\derived\\tcha_stations.shp\"\n",
    "locdf = gpd.read_file(locationFilePath)\n",
    "locdf = locdf.set_index([\"locId\", 'stnId'])\n",
    "locationNameList = list(locdf['Place'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters of the fitted distribution are contained in another data file, and this is indexed using the TCRM location id number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramFile = \"X:/georisk/HaRIA_B_Wind/projects/tcha/data/derived/parameters.csv\"\n",
    "rlupperFile = \"X:/georisk/HaRIA_B_Wind/projects/tcha/data/derived/fitted_rl_u.csv\"\n",
    "rllowerFile = \"X:/georisk/HaRIA_B_Wind/projects/tcha/data/derived/fitted_rl_l.csv\"\n",
    "rlmeanFile = \"X:/georisk/HaRIA_B_Wind/projects/tcha/data/derived/fitted_rl.csv\"\n",
    "\n",
    "paramNames = ['locId', \"locName\", \"it_shape\", \"it_thresh\", \"it_scale\", \n",
    "              \"it_rate\", \"gpd_rate\", \"gpd_shape\", \"gpd_thresh\", \"gpd_scale\"]\n",
    "gpddf = pd.read_csv(paramFile, names=paramNames, skiprows=1, index_col='locId')\n",
    "\n",
    "rlciNames = ['locId'\"locName\", \"RP1\", \"RP2\", \"RP5\", \"RP10\", \"RP20\", \"RP50\",\n",
    "             \"RP100\", \"RP200\", \"RP500\", \"RP1000\", \"RP2000\", \"RP5000\" \"RP10000\"]\n",
    "rludf = pd.read_csv(rlupperFile, index_col='locId')\n",
    "rlldf = pd.read_csv(rllowerFile, index_col='locId')\n",
    "rldf = pd.read_csv(rlmeanFile, index_col='locId')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotObservedHazard(locId, ax):\n",
    "    obsdf = loadObservations(locId)\n",
    "    if obsdf is None:\n",
    "        return ax\n",
    "    numYears = getStationDates(locId)\n",
    "    data = np.zeros(int(numYears * 365.25))\n",
    "    wspd = np.sort(np.array(obsdf['gust'])) # Include conversion to 0.2 second wind gust\n",
    "    data[-len(wspd):] = wspd\n",
    "    emprp = empReturnPeriod(data)\n",
    "    \n",
    "    ax.scatter(emprp[emprp > 1], data[emprp > 1], s=50,\n",
    "                color='k', marker='x', label=\"Empirical ARI\", zorder=100)\n",
    "    return ax\n",
    "\n",
    "    \n",
    "def loadSimulations(locId):\n",
    "    fname = pjoin(\"X:/georisk/HaRIA_B_Wind/projects/tcha/data/derived/hazard/empirical\", \"{0:d}_empari.csv\".format(locId))\n",
    "    try:\n",
    "        df = pd.read_csv(fname, names=['ARI', 'wspd'], skiprows=1)\n",
    "    except IOError:\n",
    "        print(\"Cannot load {0}\".format(fname))\n",
    "        \n",
    "    return df\n",
    "\n",
    "def plotSimulatedHazard(locId, ax):\n",
    "    simdf = loadSimulations(locId)\n",
    "    \n",
    "    ari = simdf['ARI'].values\n",
    "    wspd = simdf['wspd'].values\n",
    "    \n",
    "    ax.scatter(ari, wspd,s=50, alpha=0.5,\n",
    "                color='r', marker='o', label=\"Simulated ARI\", zorder=1)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotFittedHazard(rval, ax, label):\n",
    "    \"\"\"\n",
    "    Plot a fitted distribution, with approximate 90% confidence interval\n",
    "    and empirical return period values.\n",
    "\n",
    "    :param data: :class:`numpy.ndarray` of observed data values.\n",
    "    :param float mu: Selected threshold value.\n",
    "    :param float xi: Fitted shape parameter.\n",
    "    :param float sigma: Fitted scale parameter.\n",
    "    :param str title: Title string for the plot.\n",
    "    :param str figfile: Path to store the file (includes image format)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    rp = np.array([1, 2, 5, 10, 20, 50, 100, 200,\n",
    "                   500, 1000, 2000, 5000, 10000])\n",
    "    #mu, xi, sigma, rate = gpd_params\n",
    "    #print(mu, xi, sigma, rate)\n",
    "    #rval = returnLevels(rp, mu, xi, sigma, rate)\n",
    "    #print(rval)\n",
    "    ax.semilogx(rp, rval, label=label)\n",
    "    \n",
    "\n",
    "    return ax\n",
    "\n",
    "def plotCI(ax, rll, rlu):\n",
    "    rp = np.array([1, 2, 5, 10, 20, 50, 100, 200,\n",
    "                   500, 1000, 2000, 5000, 10000])\n",
    "    ax.fill_between(rp, rlu, rll, alpha=0.25, label=\"90% CI\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadParameters(locationName, showCategories=True, showWindRegions=True):\n",
    "    locId = locdf.index[locationNameList.index(locationName)][0]   \n",
    "    try:\n",
    "        stnId = locdf.loc[locId].index[0]\n",
    "    except KeyError:\n",
    "        print(\"No index for given location id: {0}\".format(locId))\n",
    "    else:\n",
    "        stnName = locdf.loc[locId, stnId]['Place']\n",
    "\n",
    "        stnObsFile = pjoin(obsPath, \"bom_{0:06d}.csv\".format(stnId))\n",
    "        if os.path.exists(stnObsFile):\n",
    "            print(\"Observation file exists for {0}\".format(stnName))\n",
    "        else:\n",
    "            print(\"No observations for {0}\".format(stnName))\n",
    "            \n",
    "    if locId in gpddf.index.values:\n",
    "        gpd_rate = gpddf.loc[locId]['gpd_rate']\n",
    "        gpd_shape = gpddf.loc[locId]['gpd_shape']\n",
    "        gpd_scale = gpddf.loc[locId]['gpd_scale']\n",
    "        gpd_thresh = gpddf.loc[locId]['gpd_thresh']\n",
    "        it_rate = gpddf.loc[locId]['it_rate']\n",
    "        it_shape = gpddf.loc[locId]['it_shape']\n",
    "        it_scale = gpddf.loc[locId]['it_scale']\n",
    "        it_thresh = gpddf.loc[locId]['it_thresh']\n",
    "        rlu = rludf.loc[locId][1:].astype(float).values\n",
    "        rll = rlldf.loc[locId][1:].astype(float).values\n",
    "        rlm = rldf.loc[locId][1:].astype(float).values\n",
    "        #print(rll)\n",
    "        #print(rlm)\n",
    "        #print(rlu)\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(9,5))\n",
    "        plotFittedHazard(rlm, ax, \"Percentile threshold fit\") #(gpd_thresh, gpd_shape, gpd_scale, gpd_rate)\n",
    "        #plotFittedHazard((it_thresh, it_shape, it_scale, it_rate), ax, \"Iterative threshold fit\")\n",
    "        plotCI(ax, rll, rlu)\n",
    "        plotObservedHazard(stnId, ax)\n",
    "        plotSimulatedHazard(locId, ax)\n",
    "        startYear = stndf.loc[stnId]['stnDataStart']\n",
    "        endYear = stndf.loc[stnId]['stnDataEnd']\n",
    "        stnWMO = stndf.loc[stnId]['stnWMONumber']\n",
    "        title_str = \"{0} ({1}: {2}-{3})\".format(stnName.replace(\"Amo\", \"Airport\"), stnWMO, startYear, endYear)  # + \"\\n\" +\n",
    "                 #r\"$\\mu$ = {0:.3f}, $\\xi$ = {1:.5f}, $\\sigma$ = {2:.4f}\".\n",
    "                 #format(mu, xi, sigma))\n",
    "        ax.set_title(title_str)\n",
    "        ax.set_ylim((0, 100))\n",
    "        ax.set_yticks(np.arange(0, 101, 10))\n",
    "        ax.set_xlim((1, 10000))\n",
    "        ax.set_ylabel('Wind speed (m/s)')\n",
    "        ax.set_xlabel('Average recurrence interval (years)')\n",
    "        ax.grid(which='major', linestyle='-')\n",
    "        ax.grid(which='minor', linestyle='--', linewidth=1)\n",
    "        \n",
    "        if showCategories:\n",
    "            ax.axhline(45.6, c='lime', linestyle='--', linewidth=2)\n",
    "            ax.axhline(62.5, c='darkorange', linestyle='--', linewidth=2)\n",
    "            ax.axhline(77.8, c='darkred', linestyle='--', linewidth=2)\n",
    "            ax.text(15000, 45.6, 'Cat 3', ha='center')\n",
    "            ax.text(15000, 62.5, 'Cat 4', ha='center')\n",
    "            ax.text(15000, 77.8, 'Cat 5', ha='center')\n",
    "            \n",
    "        if showWindRegions:\n",
    "            rp = np.array([1, 2, 5, 10, 20, 50, 100, 200,\n",
    "                           500, 1000, 2000, 5000, 10000])\n",
    "            rpd = 156 - 142 * np.power(rp, -0.1)\n",
    "            rpc = 122 - 104 * np.power(rp, -0.1)\n",
    "            rpb = 106 - 92 * np.power(rp, -0.1)\n",
    "\n",
    "            rpd[np.where(rp>=50)] = rpd[np.where(rp>=50)]*1.1\n",
    "            rpc[np.where(rp>=50)] = rpc[np.where(rp>=50)]*1.05\n",
    "\n",
    "            ax.semilogx(rp[2:], rpd[2:], color='0.75', linestyle=\"--\", label='AS/NZS 1170.2 Region D')\n",
    "            ax.semilogx(rp[2:], rpc[2:], color='0.5', linestyle=\"--\", label='AS/NZS 1170.2 Region C')\n",
    "            \n",
    "        ax.legend(loc=2)\n",
    "        plt.savefig(pjoin(\"X:/georisk/HaRIA_B_Wind/projects/tcha/data/derived/plots/validation/\", \"ari_{0}.tif\".format(stnId)), bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No index in GPD parameter file for {0}\".format(locId))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(loadParameters, locationName=locationNameList, \n",
    "         showCategories=Checkbox(value=False, description=\"Show TC categories\"),\n",
    "         showWindRegions=Checkbox(value=True, description=\"Show wind loading regions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
